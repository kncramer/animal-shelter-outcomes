











# imports
import pandas as pd
import numpy as np





# reading in shelter intakes
intakes =  pd.read_csv('../data/austin_animal_center_intakes_20241017.csv')
intakes.head()


intakes.info()





# dropping inconsequential columns
intakes.drop(columns=['Name', 'MonthYear'], inplace=True)


# renaming columns to be intake specific and snake case
columns = {
    'Animal ID': 'animal_id',
    'DateTime': 'intake_time',
    'Found Location': 'found_location',
    'Intake Type': 'intake_type',
    'Intake Condition': 'intake_condition',
    'Animal Type': 'animal_type',
    'Sex upon Intake': 'intake_gender',
    'Age upon Intake': 'intake_age',
    'Breed': 'intake_breed',
    'Color': 'intake_color'    
}

intakes = intakes.rename(columns=columns)


# converting intake_time column to datetime format
intakes['intake_time'] = pd.to_datetime(intakes['intake_time'], format='%m/%d/%Y %I:%M:%S %p')


intakes.nunique()





# sort intakes by most recent intakes first
intakes.sort_values(by=['intake_time', 'animal_id'], inplace=True, ascending = False)


# creating a dataframe for repeat animals - note the keeping the first
repeat_intakes = intakes[intakes.duplicated(subset=['animal_id'], keep=False)].sort_values(by=['animal_id'])

# drop duplicate observations
intakes.drop_duplicates(subset='animal_id', inplace = True, keep=False)





# reading in shelter outcomes
outcomes = pd.read_csv('../data/austin_animal_center_outcomes_20241017.csv')
outcomes.head()


outcomes.info()





# dropping inconsequential columns
outcomes.drop(columns=['Name', 'MonthYear', 'Outcome Subtype'], inplace=True)


# renaming columns to be outcome specific and snake case
outcome_columns = {
    'Animal ID': 'animal_id',
    'DateTime': 'outcome_time',
    'Date of Birth': 'date_of_birth',
    'Outcome Type': 'outcome_type',
    'Animal Type': 'outcome_animal_type',
    'Sex upon Outcome': 'outcome_gender',
    'Age upon Outcome': 'outcome_age',
    'Breed': 'outcome_breed',
    'Color': 'outcome_color'    
}

outcomes = outcomes.rename(columns=outcome_columns)


# converting outcome_time and date of birth columns to datetime format
outcomes['outcome_time'] = pd.to_datetime(outcomes['outcome_time'], format='%m/%d/%Y %I:%M:%S %p')
outcomes['date_of_birth'] = pd.to_datetime(outcomes['date_of_birth'], format='%m/%d/%Y')


outcomes.nunique()





# sort intakes by most recent intakes first
outcomes.sort_values(by=['outcome_time', 'animal_id'], inplace=True, ascending = False)


# creating a dataframe for repeat animals - note the keeping the first
repeat_outcomes = outcomes[outcomes.duplicated(subset=['animal_id'], keep=False)].sort_values(by=['animal_id'])

# drop duplicate observations
outcomes.drop_duplicates(subset='animal_id', inplace = True, keep=False)








# adding temporary column to indicate intakes and outcomes
repeat_intakes['intakes'] = 'intakes'
repeat_outcomes['intakes'] = 'outcomes'


# checking for missing values and shape
repeat_intakes.isna().sum().sum(), repeat_intakes.shape


# checking for missing values and shape
repeat_outcomes.isna().sum().sum(), repeat_outcomes.shape


# finding na values
repeat_outcomes.isna().sum()


# dropping missing values in outcome_type
repeat_outcomes.dropna(subset=['outcome_type'], inplace=True)


# The two dataframes are concat together.  This allows to sort all observations sequentially.
# A column is added to create a date column.
df = pd.concat([repeat_intakes, repeat_outcomes])
df['sequential_date'] = df['outcome_time']
df['sequential_date'] = df['sequential_date'].fillna(df['intake_time'])

df.sort_values(by=['animal_id','sequential_date'], inplace=True, ascending=False)
df.info()


# split intakes and outcomes for sequential identifiers
df1 = df[df['intakes'] == 'intakes'].copy()
df2 = df[df['intakes'] == 'outcomes'].copy()
df1.shape, df2.shape


# dropping empty columns manually to control which are dropped
df1_cols_drop = ['outcome_time', 'date_of_birth', 'outcome_type',
       'outcome_animal_type', 'outcome_gender', 'outcome_age', 'outcome_breed',
       'outcome_color']

df2_cols_drop = ['intake_time', 'found_location', 'intake_type',
       'intake_condition', 'animal_type', 'intake_gender', 'intake_age',
       'intake_breed', 'intake_color']

df1.drop(columns=df1_cols_drop, inplace=True)
df2.drop(columns=df2_cols_drop, inplace=True)
df1.shape, df2.shape


# creating a unique identifier, animal_stay, to tie with outcomes
df1.sort_values(by=['animal_id', 'sequential_date'], inplace=True)
df1['stay'] = df1.groupby('animal_id').cumcount() +1 
df1['stay'] = df1['stay'].astype('str')
df1['animal_stay'] = df1['animal_id'] + '-' + df1['stay']
df1.shape


# creating a unique identifier, animal_stay, to tie with intakes
df2.sort_values(by=['animal_id', 'sequential_date'], inplace=True)
df2['stay'] = df2.groupby('animal_id').cumcount() +1 
df2['stay'] = df2['stay'].astype('str')
df2['animal_stay'] = df2['animal_id'] + '-' + df2['stay']
df2.shape


# merging the two dataframes
repeats = pd.merge(left=df2, right=df1, how='inner', on='animal_stay')
repeats.shape


repeats.columns


# cleaning up column namesf and adding repeats column indicator
repeats.drop(columns=['intakes_x', 'sequential_date_x', 'stay_x', 'animal_id_y', 'intakes_y', 'sequential_date_y'], inplace=True)
repeats = repeats.rename(columns={'animal_id_x': 'animal_id', 'stay_y': 'stay'})
repeats['stay'] = repeats['stay'].astype(int)
repeats['repeat'] = 1


repeats.info()


# meging intakes and outcomes dataframes
intakes_outcomes = pd.merge(left=outcomes, right=intakes, how='inner', on='animal_id')
intakes_outcomes['stay'] = 1
intakes_outcomes['repeat'] = 0
intakes_outcomes['animal_stay'] = intakes_outcomes['animal_id'] + '-' + intakes_outcomes['stay'].astype('str')
intakes_outcomes.info()


# merging the two dataframes
austin = pd.concat([intakes_outcomes, repeats])
austin.shape


austin.isna().sum()


print(austin.isna().sum().sum())
austin.dropna(inplace=True)
print(austin.isna().sum().sum())


# adding column for stay duration
austin['stay_duration'] = austin['outcome_time'] - austin['intake_time']

# convert stay_duration to number of days
austin['stay_duration'] = austin['stay_duration'].dt.days.astype(int)

# check for negative stay_duration
austin[austin['stay_duration'] < 0]['stay_duration'].value_counts()





# change -1 day stay durations to 0
austin['stay_duration'] = austin['stay_duration'].map(lambda x: 0 if x == -1 else x)

# drop observations with a negative stay duration
print(austin.shape)
austin = austin[austin['stay_duration'] >= 0]
print(austin.shape)


# check for durations over 365
austin[austin['stay_duration'] <= 365]['stay_duration'].value_counts()


len(austin[austin['stay_duration'] > 365])





print(austin.shape)
austin = austin[austin['stay_duration'] <= 365]
print(austin.shape)


# compare intake/outcome animal_type, gender, breed, and color
print(f'Number of animal type changes: {austin[austin['animal_type'] != austin['outcome_animal_type']].shape[0]}')
print(f'Number of neuters/spays: {austin[austin['intake_gender'] != austin['outcome_gender']].shape[0]}')
print(f'Number of breed changes: {austin[austin['intake_breed'] != austin['outcome_breed']].shape[0]}')
print(f'Number of color changes: {austin[austin['intake_color'] != austin['outcome_color']].shape[0]}')





# dropping duplicate columns
austin.drop(columns=['outcome_animal_type', 'outcome_breed', 'outcome_color'], inplace=True)

# renaming columns without intake specifier
austin.rename(columns={'intake_breed': 'breed', 'intake_color': 'color'}, inplace=True)


# adding column for animals spayed-neutered while in shelters
austin['spay_neuter'] = (austin['intake_gender'] != austin['outcome_gender']).astype(int)


# function for converting age columns to age in months
def convert_age(age): 
    '''
    Convert an age in string to age in months.
   
    Argument:
    age(str): The animal age in str format, eg. '7 years'.
   
    Return:
    float: The age converted to months. Return 0 if the unit is not list int the fucntion.
    '''
    value, unit = age.split()
    value = abs(int(value)) # assume the nagetive age is typo 
    
    if 'year' in unit:
        return value * 12
    elif 'month' in unit:
        return value
    elif 'week' in unit:
        return round(float(value * 0.23), 2)
    elif 'day' in unit:
        return round(float(value * 0.033), 2)
    else:
        return 0


austin['intake_age'] = austin['intake_age'].map(convert_age)
austin['outcome_age'] = austin['outcome_age'].map(convert_age)


# checking animal types
austin['animal_type'].value_counts(normalize=True)


# see breeds under Other animal type
austin[austin['animal_type'] == 'Other']['breed'].unique()





# dropping obsevations that aren't cats or dogs
print(austin.shape)
austin = austin[austin['animal_type'] != 'Other']
austin = austin[austin['animal_type'] != 'Bird']
austin = austin[austin['animal_type'] != 'Livestock']
austin.shape


# checking remaining null values
austin.isnull().sum()


austin.head()


# saving combined data to use in other notebooks
austin.to_csv('../data/austin-data.csv', index=False)





# reading in data for 2014-2015
dallas_2014 = pd.read_csv('../data/Dallas_Animal_Shelter_Data_Fiscal_Year_2014_-_2015_20241028.csv')


pd.set_option('display.max_columns', 35)
dallas_2014.head()





# function to convert column names
def to_snake_case(columns):
    '''
    Convert dataframe column names to snake case

    Keyword arguments:
    columns -- original column names of dataframe

    Returns a dictionary to pass into pandas rename function
    '''
    return {column: column.lower().replace(' ', '_') for column in columns}


dallas_2014.rename(columns = to_snake_case(dallas_2014.columns), inplace = True)


# converting intake_date and outcome_date to datetime
dallas_2014['intake_date'] = pd.to_datetime(dallas_2014['intake_date'], format='%m/%d/%Y %I:%M:%S %p')
dallas_2014['outcome_date'] = pd.to_datetime(dallas_2014['outcome_date'], format='%m/%d/%Y %I:%M:%S %p')

# sorting by outcome_date with most recent first
dallas_2014.sort_values(by = 'outcome_date', ascending = False, inplace = True)





# function to read in data from remainging years
def read_in_dallas_data(year):
    '''
    Function to read in csv data for animal shelter data by year

    Keyword arguments:
    year -- which year to bring in data from

    Returns dataframe with column names converted to snake case,
    intake and outcome dates converted to datetime,
    and sorted by outcome date descending.
    '''
    year = str(year)
    # read in data
    if year != '2023':
        df = pd.read_csv('../data/Dallas_Animal_Shelter_Data_Fiscal_Year_'+year+'_-_'+str(int(year)+1)+'_20241028.csv', low_memory=False)
    else:
        df = pd.read_csv('../data/Dallas_Animal_Shelter_Data_Fiscal_Year_'+year+'_-_'+str(int(year)+2)+'_20241028.csv', low_memory=False)
    # convert column names
    df.rename(columns=to_snake_case(df.columns), inplace = True)
    # convert intake and outcome dates to datetime
    df['intake_date'] = pd.to_datetime(df['intake_date'], format='mixed')
    df['outcome_date'] = pd.to_datetime(df['outcome_date'], format='mixed')
    # sort by outcome_date
    df.sort_values(by = 'outcome_date', ascending = False, inplace = True)
    return df


dallas_2015 = read_in_dallas_data(2015)
dallas_2016 = read_in_dallas_data(2016)
dallas_2017 = read_in_dallas_data(2017)
dallas_2018 = read_in_dallas_data(2018)
dallas_2019 = read_in_dallas_data(2019)
dallas_2020 = read_in_dallas_data(2020)
dallas_2021 = read_in_dallas_data(2021)
dallas_2022 = read_in_dallas_data(2022)
dallas_2023 = read_in_dallas_data(2023)


dallas_combined = pd.concat([dallas_2014, dallas_2015, dallas_2016, dallas_2017, dallas_2018,
                             dallas_2019, dallas_2020, dallas_2021, dallas_2022, dallas_2023])


# resorting combined dataframe by outcome date
dallas_combined.sort_values(by = 'outcome_date', ascending = False, inplace = True)

# dropping duplicates by animal_id to focus on most recent observation per unique animal
print(dallas_combined.shape)
dallas_combined.drop_duplicates(subset = 'animal_id', inplace = True)
print(dallas_combined.shape)
dallas_combined.head()


dallas_combined.info()





dallas_combined.drop(columns = ['kennel_number', 'kennel_status', 'tag_type', 'activity_number',
                                'activity_sequence', 'source_id', 'census_tract', 'council_district',
                                'intake_subtype', 'intake_total', 'staff_id', 'intake_time', 'due_out',
                                'hold_request', 'outcome_time', 'receipt_number', 'impound_number',
                                'service_request_number', 'additional_information', 'month', 'year',
                                'outcome_subtype'], inplace = True)


# see animal types
dallas_combined['animal_type'].value_counts()





# dropping all animal types that aren't cats or dogs
print(dallas_combined.shape)
dallas_combined = dallas_combined[dallas_combined['animal_type'] != 'WILDLIFE']
dallas_combined = dallas_combined[dallas_combined['animal_type'] != 'BIRD']
dallas_combined = dallas_combined[dallas_combined['animal_type'] != 'LIVESTOCK']
dallas_combined = dallas_combined[dallas_combined['animal_type'] != 'D']
print(dallas_combined.shape)


# see remainging null values
dallas_combined.isnull().sum()





# drop null outcome date rows
dallas_combined.dropna(subset = 'outcome_date', inplace = True)

# column for stay duration
dallas_combined['stay_duration'] = dallas_combined['outcome_date'] - dallas_combined['intake_date']
# convert to number of days
dallas_combined['stay_duration'] = dallas_combined['stay_duration'].dt.days.astype(int)

# check for negative stay_duration
dallas_combined[dallas_combined['stay_duration'] < 0]['stay_duration'].value_counts()





dallas_combined = dallas_combined[dallas_combined['stay_duration'] >= 0]





dallas_combined['reason'].unique()


dallas_combined['outcome_condition'].unique()


dallas_combined['chip_status'].value_counts()


dallas_combined['animal_origin'].unique()





dallas_combined.isnull().sum()


# drop chip_status and animal_origin columns
dallas_combined = dallas_combined.drop(columns=['chip_status', 'animal_origin'])

# fill nulls for reason and outcome_condition
dallas_combined = dallas_combined.fillna({'reason': 'NONE', 'outcome_condition': 'HEALTHY'})

# drop null breed observations
dallas_combined.dropna(subset = 'animal_breed', inplace = True)


dallas_combined.info()


# saving combined data
dallas_combined.to_csv('../data/dallas-combined-shelter-data.csv', index=False)



