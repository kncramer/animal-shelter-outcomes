





import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import OneHotEncoder
from sklearn.linear_model import LogisticRegression


# read in the data
df = pd.read_csv('../data/austin-data.csv')
df.info()


df.head()


# Examine features for selection
df.columns


# Select relevant features for modeling
df_lr = df[['outcome_type', 'outcome_gender', 'intake_type', \
'animal_type', 'intake_gender', 'intake_age', 'breed', 'stay_duration', \
            'spay_neuter', 'repeat']]


# Setup feature matrix and target variable
X = df_lr.drop(columns='repeat')
y = df_lr['repeat']





# Check for distribution of target
df_lr['repeat'].value_counts(normalize=True)


# Train, test, split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=27, stratify=y)


# Converting categorical features to numerical
ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)
ohe.fit(X_train)


# Transforming training and testing data
X_train_ohe = ohe.transform(X_train)
X_test_ohe = ohe.transform(X_test)
X_train_ohe.shape, X_test_ohe.shape


# Putting data back into Dataframes
X_train_ohe = pd.DataFrame(X_train_ohe, columns=ohe.get_feature_names_out())
X_test_ohe = pd.DataFrame(X_test_ohe, columns=ohe.get_feature_names_out())
X_train_ohe.head()


# Instantiate and Fit model
lr = LogisticRegression(max_iter=200)
lr.fit(X_train_ohe, y_train)


# Make predictions
lr.predict(X_test_ohe)

# Create probabilities
np.round(lr.predict_proba(X_test_ohe), decimals=4)[:10]


# Evaluate model
f'Training data {round(lr.score(X_train_ohe, y_train) *100,2)}%'


f'Testing data {round(lr.score(X_test_ohe, y_test)*100,2)}%'


f'Null Model {round(df_lr['repeat'].value_counts(normalize=True)[0] *100, 2)}%.'





# create parameters for gridsearch
grid_params = {
    'penalty': ['l1','l2'],
    'C': [0.5, 1.0], 
    'class_weight': [{0:0.81, 1:0.19}], 
    'random_state': [42],
    'solver': ['liblinear', 'saga'],
    'max_iter': [200],
    'n_jobs': [-1],
}


# instantiate gridsearch
lr_gs = GridSearchCV(LogisticRegression(),
                    grid_params,
                    cv=3,
                    verbose=1)


# fit gridsearch
lr_gs.fit(X_train_ohe, y_train);


# which parameter settings led to best result
lr_gs.best_params_


# best result
lr_gs.best_score_


# evaluate model
lr_gs.score(X_test_ohe, y_test)






